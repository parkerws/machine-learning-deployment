{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries for the model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the data file using pandas\n",
    "\n",
    "cols = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']\n",
    "\n",
    "df = pd.read_csv('auto-mpg.data', names=cols, na_values='?',\n",
    "                comment= '\\t',\n",
    "                sep=' ',\n",
    "                skipinitialspace=True)\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "#splitting the data using StratifiedShuffleSplit from sklearn\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"Cylinders\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>6</td>\n",
       "      <td>146.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower  Weight  Acceleration  Model Year  \\\n",
       "145          4          83.0        61.0  2003.0          19.0          74   \n",
       "151          4          79.0        67.0  2000.0          16.0          74   \n",
       "388          4         156.0        92.0  2585.0          14.5          82   \n",
       "48           6         250.0        88.0  3139.0          14.5          71   \n",
       "114          4          98.0        90.0  2265.0          15.5          73   \n",
       "..         ...           ...         ...     ...           ...         ...   \n",
       "147          4          90.0        75.0  2108.0          15.5          74   \n",
       "156          8         400.0       170.0  4668.0          11.5          75   \n",
       "395          4         135.0        84.0  2295.0          11.6          82   \n",
       "14           4         113.0        95.0  2372.0          15.0          70   \n",
       "362          6         146.0       120.0  2930.0          13.8          81   \n",
       "\n",
       "     Origin  \n",
       "145       3  \n",
       "151       2  \n",
       "388       1  \n",
       "48        1  \n",
       "114       2  \n",
       "..      ...  \n",
       "147       2  \n",
       "156       1  \n",
       "395       1  \n",
       "14        3  \n",
       "362       3  \n",
       "\n",
       "[318 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separating the target variable from the features\n",
    "data = strat_train_set.drop(\"MPG\", axis=1)\n",
    "data_labels = strat_train_set[\"MPG\"].copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the Origin column to contain actual labels rather than their numerical representations\n",
    "def preprocess_origin_cols(df):\n",
    "    df[\"Origin\"] = df[\"Origin\"].map({1: \"India\", 2: \"USA\", 3: \"Germany\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of custom attribute adder class, to automate the creation of different features, such as the \n",
    "#correlation of acceleration to horsepower and number of cylinders\n",
    "acc_ix, hpower_ix, cyl_ix = 4,2, 0\n",
    "\n",
    "class CustomAttrAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, acc_on_power=True): # no *args or **kargs\n",
    "        self.acc_on_power = acc_on_power\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        acc_on_cyl = X[:, acc_ix] / X[:, cyl_ix]\n",
    "        if self.acc_on_power:\n",
    "            acc_on_power = X[:, acc_ix] / X[:, hpower_ix]\n",
    "            return np.c_[X, acc_on_power, acc_on_cyl]\n",
    "        \n",
    "        return np.c_[X, acc_on_cyl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_pipeline_transformer(data):\n",
    "    '''\n",
    "    Function that processes numerical transformations\n",
    "    Argument:\n",
    "        data: original dataframe\n",
    "    Returns:\n",
    "        num_attrs: numerical dataframe\n",
    "        num_pipeline: numerical pipeline object\n",
    "    '''\n",
    "\n",
    "    numerics = ['float64', 'int64']\n",
    "\n",
    "    num_attrs = data.select_dtypes(include=numerics)\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")), #Uses median values to fill in null/missing values\n",
    "        ('attrs_adder', CustomAttrAdder()), #Adds additional custom attributes from the custom class created prior\n",
    "        ('std_scaler', StandardScaler()), #Scales data appropriately to use the model\n",
    "        ])\n",
    "    return num_attrs, num_pipeline\n",
    "\n",
    "def pipeline_transformer(data):\n",
    "    '''\n",
    "    Completes the transformation pipeline for both numerical and categorical data.\n",
    "    \n",
    "    Argument:\n",
    "        data: original dataframe\n",
    "    Returns:\n",
    "        prepared_data: transformed data, ready to use\n",
    "    '''\n",
    "    cat_attrs = [\"Origin\"]\n",
    "    num_attrs, num_pipeline = num_pipeline_transformer(data) #Call to previous function to handle numerical data\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, list(num_attrs)),\n",
    "        (\"cat\", OneHotEncoder(), cat_attrs), #One Hot encodes the categorical data, in this case, the origin column\n",
    "        ])\n",
    "    prepared_data = full_pipeline.fit_transform(data)\n",
    "    return prepared_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From raw data to processed data in 2 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85657842, -1.07804475, -1.15192977, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.85657842, -1.1174582 , -0.9900351 , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.85657842, -0.3587492 , -0.31547399, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.85657842, -0.56566984, -0.53133355, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.85657842, -0.78244384, -0.23452666, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.32260746, -0.45728283,  0.44003446, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = preprocess_origin_cols(data)\n",
    "prepared_data = pipeline_transformer(preprocessed_df)\n",
    "prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.85657842, -1.07804475, -1.15192977, -1.17220298,  1.21586943,\n",
       "       -0.54436373,  1.70952741,  1.29565517,  1.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 4 different models\n",
    "1. Linear Regression\n",
    "2. Decision Tree\n",
    "3. Random Forest\n",
    "4. SVM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Samples:  [29.08069379 27.78336755 26.08031176 12.70419279 22.23454159]\n",
      "Actual Labels of Samples:  [32.0, 31.0, 26.0, 18.0, 26.0]\n"
     ]
    }
   ],
   "source": [
    "#Creating sample data to test predictions\n",
    "\n",
    "sample_data = data.iloc[:5]\n",
    "sample_labels = data_labels.iloc[:5]\n",
    "\n",
    "sample_data_prepared = pipeline_transformer(sample_data)\n",
    "\n",
    "print(\"Prediction of Samples: \", lin_reg.predict(sample_data_prepared))\n",
    "print(\"Actual Labels of Samples: \", list(sample_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9590402225760872"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Calculating the Mean Squared Error of the predictions\n",
    "\n",
    "\n",
    "mpg_predictions = lin_reg.predict(prepared_data)\n",
    "lin_mse = mean_squared_error(data_labels, mpg_predictions) #Calculating MSE by plugging the actual values with predictions\n",
    "lin_rmse = np.sqrt(lin_mse) #Converting to the root MSE with numpy\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg_predictions = tree_reg.predict(prepared_data)\n",
    "tree_mse = mean_squared_error(data_labels, mpg_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree predictions seemingly indicate that the root mean squared error is 0, or a perfect prediction. This is unlikely, and it is likely that the model has been **overfit**\n",
    "\n",
    "To check out what is happening, we will use **Cross Validation** to take K-folds and randomly split the data. The result are K evaluation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96642672, 2.98862427, 3.42057196, 3.5       , 2.2192341 ,\n",
       "       2.98092897, 2.87326034, 3.68400258, 4.16962905, 2.64123627])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg,\n",
    "                        prepared_data,\n",
    "                        data_labels,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        cv = 10)\n",
    "tree_reg_rmse_scores = np.sqrt(-scores)\n",
    "tree_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1443914257175143"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.43254597, 3.45157629, 3.6621715 , 2.59652976, 2.48023405,\n",
       "       2.74798115, 3.32524647, 2.42208917, 3.78133275, 2.8573747 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, prepared_data, data_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_reg_rmse_scores = np.sqrt(-scores)\n",
    "lin_reg_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0757081793709324"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6098723114018525"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(prepared_data, data_labels)\n",
    "forest_reg_cv_scores = cross_val_score(forest_reg,\n",
    "                                      prepared_data,\n",
    "                                      data_labels,\n",
    "                                      scoring=\"neg_mean_squared_error\",\n",
    "                                      cv = 10)\n",
    "\n",
    "forest_reg_rmse_scores = np.sqrt(-forest_reg_cv_scores)\n",
    "forest_reg_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.08659162080283"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel='linear')\n",
    "svm_reg.fit(prepared_data, data_labels)\n",
    "svm_cv_scores = cross_val_score(svm_reg,\n",
    "                               prepared_data,\n",
    "                               data_labels,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               cv = 10)\n",
    "svm_rmse_scores = np.sqrt(-svm_cv_scores)\n",
    "svm_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Hyperparameters with GridSearchCV\n",
    "\n",
    "A model parameter is a configuration variable that is internal to the model and whose value can be estimated from the data. They are similar to the parameters passed into a function in programming, but in this case, parameters passed into the model.\n",
    "\n",
    "Some examples of parameters:\n",
    " - Weights in an artificial neural network\n",
    " - The support vectors in a support vector machine\n",
    " - The coefficients in a linear regression or a logistic regression \n",
    "\n",
    "A model hyperparameter is a configuration external to the model and whose vlaue cannot be estimated from the data. They are often used in processes to help estimate model parameters, specified by the practionoer, and used to tune for a given predictive modeling problem. \n",
    "\n",
    " - The learning rate for training a neural network\n",
    " - The C and sigma hyperparameters for support vector machines\n",
    " - The k in k-nearest-neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2,4,6,8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3,10], 'max_features': [2,3,4]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid,\n",
    "                          scoring=\"neg_mean_squared_error\",\n",
    "                          return_train_score=True,\n",
    "                          cv=10,\n",
    "                          )\n",
    "\n",
    "grid_search.fit(prepared_data, data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5187844773484875 {'max_features': 2, 'n_estimators': 3}\n",
      "3.211778715939392 {'max_features': 2, 'n_estimators': 10}\n",
      "2.9105214634652867 {'max_features': 2, 'n_estimators': 30}\n",
      "3.315262103306475 {'max_features': 4, 'n_estimators': 3}\n",
      "2.755952110667078 {'max_features': 4, 'n_estimators': 10}\n",
      "2.759392668661999 {'max_features': 4, 'n_estimators': 30}\n",
      "3.1999721380955513 {'max_features': 6, 'n_estimators': 3}\n",
      "2.7242450807665315 {'max_features': 6, 'n_estimators': 10}\n",
      "2.7363377021006157 {'max_features': 6, 'n_estimators': 30}\n",
      "2.9871191513518105 {'max_features': 8, 'n_estimators': 3}\n",
      "2.807615802052603 {'max_features': 8, 'n_estimators': 10}\n",
      "2.7043668758829225 {'max_features': 8, 'n_estimators': 30}\n",
      "3.3492312082595803 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "2.9496329733408113 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "3.3778952469375296 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "2.926125667392118 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "2.9812849075223906 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "3.0260591887320505 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_scores = grid_search.cv_results_\n",
    "\n",
    "#Print all parameters along with their scores\n",
    "for mean_score, params in zip(cv_scores['mean_test_score'], cv_scores['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19231428, 0.37095856, 0.11334791, 0.15238502, 0.01082228,\n",
       "       0.10766943, 0.02626149, 0.01823942, 0.00336293, 0.00153805,\n",
       "       0.00310062])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking feature importance\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acc_on_power', 0.026261494778480495),\n",
       " ('acc_on_cyl', 0.018239422657943385),\n",
       " ('Weight', 0.1523850226431066),\n",
       " ('Model Year', 0.10766943133400218),\n",
       " ('Horsepower', 0.11334790982496806),\n",
       " ('Displacement', 0.370958560857639),\n",
       " ('Cylinders', 0.19231427606021886),\n",
       " ('Acceleration', 0.010822279312477564)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attrs = ['acc_on_power', 'acc_on_cyl']\n",
    "numerics = ['float64', 'int64']\n",
    "num_attrs = list(data.select_dtypes(include=numerics))\n",
    "\n",
    "attrs = num_attrs + extra_attrs\n",
    "sorted(zip(attrs, feature_importances), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the system on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.052067423166723"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop('MPG', axis=1)\n",
    "y_test = strat_test_set['MPG'].copy()\n",
    "\n",
    "X_test_preprocessed = preprocess_origin_cols(X_test)\n",
    "X_test_prepared = pipeline_transformer(X_test_preprocessed)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a function to initiate the entire process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mpg(config, model):\n",
    "    \n",
    "    if type(config) == dict:\n",
    "        df = pd.DataFrame(config)\n",
    "    else:\n",
    "        df = config\n",
    "        \n",
    "    preproc_df = preprocess_origin_cols(df)\n",
    "    prepared_df = pipeline_transformer(preproc_df)\n",
    "    y_pred = model.predict(prepared_df)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.71      , 17.85666667, 19.20333333])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the function on a random sample\n",
    "vehicle_config = {\n",
    "    'Cylinders': [4,6,8],\n",
    "    'Displacement': [155.0, 160.0, 165.5],\n",
    "    'Horsepower': [93.0, 130.0, 98.0],\n",
    "    'Weight': [2500.0, 3150.0, 2600.0],\n",
    "    'Acceleration': [15.0, 14.0, 16.0],\n",
    "    'Model Year': [81, 80, 78],\n",
    "    'Origin': [3, 2, 1]\n",
    "}\n",
    "\n",
    "predict_mpg(vehicle_config, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(final_model, f_out)\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.71      , 17.85666667, 19.20333333])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the model from the saved file\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    model = pickle.load(f_in)\n",
    "    \n",
    "predict_mpg(vehicle_config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"mpg_prediction\": [\\n    34.080000000000005, \\n    18.936666666666667, \\n    18.683333333333334\\n  ]\\n}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:5000/predict\"\n",
    "r = requests.post(url, json = vehicle_config)\n",
    "r.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlproj_env",
   "language": "python",
   "name": "mlproj_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
